{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.pieriandata.com\"><img src=\"../Pierian_Data_Logo.PNG\"></a>\n",
    "<strong><center>Copyright by Pierian Data Inc.</center></strong> \n",
    "<strong><center>Created by Jose Marcial Portilla.</center></strong>\n",
    "# Deep Learning for Image Classification Assessment\n",
    "\n",
    "\n",
    "Welcome to your assessment! Follow the instructions in bold below to complete the assessment.\n",
    "\n",
    "If you get stuck, check out the solutions video and notebook. (Make sure to run the solutions notebook before posting a question to the QA forum please, thanks!)\n",
    "\n",
    "------------\n",
    "\n",
    "## The Challenge\n",
    "\n",
    "**Your task is to build an image classifier with Keras and Convolutional Neural Networks for the Fashion MNIST dataset. This data set includes 10 labels of different clothing types with 28 by 28 *grayscale* images. There is a training set of 60,000 images and 10,000 test images.**\n",
    "\n",
    "    Label\tDescription\n",
    "    0\t    T-shirt/top\n",
    "    1\t    Trouser\n",
    "    2\t    Pullover\n",
    "    3\t    Dress\n",
    "    4\t    Coat\n",
    "    5\t    Sandal\n",
    "    6\t    Shirt\n",
    "    7\t    Sneaker\n",
    "    8\t    Bag\n",
    "    9\t    Ankle boot\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "**TASK 1: Run the code below to download the dataset using Keras.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Data\n",
    "\n",
    "**TASK 2: Use matplotlib to view an image from the data set. It can be any image from the data set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff261cab970>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Data\n",
    "\n",
    "**TASK 3: Normalize the X train and X test data by dividing by the max value of the image arrays.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=x_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4: Reshape the X arrays to include a 4 dimension of the single channel. Similar to what we did for the numbers MNIST data set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.reshape(60000, 28, 28,1)\n",
    "x_test=x_test.reshape(10000, 28, 28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 5: Convert the y_train and y_test values to be one-hot encoded for categorical analysis by Keras.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_c=to_categorical(y_train)\n",
    "y_test_c=to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model\n",
    "\n",
    "**TASK 5: Use Keras to create a model consisting of at least the following layers (but feel free to experiment):**\n",
    "\n",
    "* 2D Convolutional Layer, filters=32 and kernel_size=(4,4)\n",
    "* Pooling Layer where pool_size = (2,2)\n",
    "\n",
    "* Flatten Layer\n",
    "* Dense Layer (128 Neurons, but feel free to play around with this value), RELU activation\n",
    "\n",
    "* Final Dense Layer of 10 Neurons with a softmax activation\n",
    "\n",
    "**Then compile the model with these parameters: loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Conv2D,MaxPool2D,Dropout,Dense,Flatten\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sbn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(filters=32,input_shape=(28,28,1),kernel_size=(3,3),activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters=64,input_shape=(28,28,1),kernel_size=(3,3),activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,activation=\"softmax\"))\n",
    "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1875/1875 [==============================] - 42s 22ms/step - loss: 0.4762 - accuracy: 0.8258 - val_loss: 0.3447 - val_accuracy: 0.8734\n",
      "Epoch 2/200\n",
      "1875/1875 [==============================] - 37s 20ms/step - loss: 0.3119 - accuracy: 0.8857 - val_loss: 0.3195 - val_accuracy: 0.8826\n",
      "Epoch 3/200\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.2694 - accuracy: 0.9015 - val_loss: 0.2726 - val_accuracy: 0.8994\n",
      "Epoch 4/200\n",
      "1875/1875 [==============================] - 40s 21ms/step - loss: 0.2390 - accuracy: 0.9116 - val_loss: 0.2594 - val_accuracy: 0.9048\n",
      "Epoch 5/200\n",
      "1875/1875 [==============================] - 40s 21ms/step - loss: 0.2176 - accuracy: 0.9193 - val_loss: 0.2481 - val_accuracy: 0.9069\n",
      "Epoch 6/200\n",
      "1875/1875 [==============================] - 43s 23ms/step - loss: 0.1974 - accuracy: 0.9258 - val_loss: 0.2579 - val_accuracy: 0.9094\n",
      "Epoch 7/200\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.1796 - accuracy: 0.9322 - val_loss: 0.2457 - val_accuracy: 0.9121\n",
      "Epoch 8/200\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.1656 - accuracy: 0.9378 - val_loss: 0.2521 - val_accuracy: 0.9116\n",
      "Epoch 9/200\n",
      "1875/1875 [==============================] - 37s 20ms/step - loss: 0.1529 - accuracy: 0.9424 - val_loss: 0.2606 - val_accuracy: 0.9138\n",
      "Epoch 10/200\n",
      "1875/1875 [==============================] - 37s 20ms/step - loss: 0.1386 - accuracy: 0.9477 - val_loss: 0.2510 - val_accuracy: 0.9162\n",
      "Epoch 11/200\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.1314 - accuracy: 0.9497 - val_loss: 0.2759 - val_accuracy: 0.9149\n",
      "Epoch 12/200\n",
      "1875/1875 [==============================] - 37s 20ms/step - loss: 0.1211 - accuracy: 0.9539 - val_loss: 0.2863 - val_accuracy: 0.9143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff261dd2760>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early=EarlyStopping(monitor=\"val_loss\",patience=5)\n",
    "model.fit(x_train,y_train_c,callbacks=[early],validation_data=(x_test,y_test_c),epochs=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "**TASK 6: Train/Fit the model to the x_train set. Amount of epochs is up to you.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1802 - acc: 0.9365\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1679 - acc: 0.9395\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.1579 - acc: 0.9439\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1502 - acc: 0.9469\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1427 - acc: 0.9496\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1397 - acc: 0.9523\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1312 - acc: 0.9551\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1274 - acc: 0.9559\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1238 - acc: 0.9582\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1201 - acc: 0.9588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c18a60e400>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Model\n",
    "\n",
    "**TASK 7: Show the accuracy,precision,recall,f1-score the model achieved on the x_test data set. Keep in mind, there are quite a few ways to do this, but we recommend following the same procedure we showed in the MNIST lecture.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'accuracy']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=np.argmax(prediction,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1, ..., 8, 1, 5])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[843,   0,  24,  20,   3,   2, 104,   0,   4,   0],\n",
       "       [  4, 980,   0,  11,   3,   0,   2,   0,   0,   0],\n",
       "       [ 12,   0, 854,   5,  56,   0,  72,   0,   1,   0],\n",
       "       [ 11,   3,  14, 921,  22,   0,  28,   0,   1,   0],\n",
       "       [  1,   0,  33,  19, 864,   0,  82,   0,   1,   0],\n",
       "       [  0,   0,   0,   0,   0, 986,   0,  12,   0,   2],\n",
       "       [ 87,   0,  54,  22,  48,   0, 783,   0,   6,   0],\n",
       "       [  0,   0,   0,   0,   0,   4,   0, 984,   0,  12],\n",
       "       [  2,   0,   4,   6,   1,   2,   4,   3, 978,   0],\n",
       "       [  1,   0,   0,   0,   0,   6,   0,  43,   0, 950]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86      1000\n",
      "           1       1.00      0.98      0.99      1000\n",
      "           2       0.87      0.85      0.86      1000\n",
      "           3       0.92      0.92      0.92      1000\n",
      "           4       0.87      0.86      0.87      1000\n",
      "           5       0.99      0.99      0.99      1000\n",
      "           6       0.73      0.78      0.75      1000\n",
      "           7       0.94      0.98      0.96      1000\n",
      "           8       0.99      0.98      0.98      1000\n",
      "           9       0.99      0.95      0.97      1000\n",
      "\n",
      "    accuracy                           0.91     10000\n",
      "   macro avg       0.92      0.91      0.91     10000\n",
      "weighted avg       0.92      0.91      0.91     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "=x_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest1=xtest1.reshape(1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction=model.predict(xtest1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, False, False, False, False, False, False,\n",
       "         True]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction>0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
